%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% alg.tex                                                              %
%                                                    início do arquivo %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{O algoritmo}\label{capalg}

O teorema\xspace\ref{maint}, com o qual encerramos o
capítulo\xspace\ref{capfund}, nos fornece por ser bicondicional
um eficiente algoritmo para
testar a irredutibilidade de um polinômio $g(x)\in\galois{q}[x]$ de grau
$n$. Em linhas gerais, o que o algoritmo faz é tentar verificar
(\ref{mainti}) e (\ref{maintii}). Vejamos:

\noindent\\
\vspace{\baselineskip}\\
\hspace{.5in}\hrulefill\\
\hspace{.5in}\textsc{Irredutível}$\bigl(g(x)\bigr)$\\
\hspace{.5in}\hrulefill\\
\hspace{.5in}\textbf{Entrada:} um polinômio $g\in\galois{q}[x]$ de grau
$n$.\\
\hspace{.5in}\textbf{Saída:} \textsl{``verdadeiro''} ou
\textsl{``falso''}.\\
\hspace{.5in}\hrulefill\\
\hspace{.5in}\texttt{1.}
\hspace{.5in} Calcule $f_1(x)\leftarrow x^{p^n}$ módulo
$g(x)$.\\
\hspace{.5in}\texttt{2.}
\hspace{.5in} Calcule $f_2(x)\leftarrow f_1(x)-x$ módulo
$g(x)$.\\
\hspace{.5in}\texttt{3.}
\hspace{.5in} Se $f_2\neq\zero$ então devolva
\textsl{``falso''}.\\
\hspace{.5in}\texttt{4.}
\hspace{.5in} Para cada $j\in[k]$:\\
\hspace{.5in}\texttt{5.}
\hspace{1in} Calcule $f_{1_j}(x)\leftarrow x^{p^{m_j}}$
módulo $g(x)$.\\
\hspace{.5in}\texttt{6.}
\hspace{1in} Calcule $f_{2_j}(x)\leftarrow f_{1_j}(x)-x$
módulo $g(x)$.\\
\hspace{.5in}\texttt{7.}
\hspace{1in} Para cada raiz $\alpha$ de $g$:\\
\hspace{.5in}\texttt{8.}
\hspace{1.5in} Calcule $f_{3_{j_{\alpha}}}(x)\leftarrow
  (x-\alpha)f_{2_j}(x)$ módulo $g(x)$.\\
\hspace{.5in}\texttt{9.}
\hspace{1.5in} Se $f_{3_{j_{\alpha}}}\neq\zero$ então devolva
\textsl{``falso''}.\\
\hspace{.5in}\hrulefill\\
\vspace{\baselineskip}

É imediato que as linhas \texttt{1}--\texttt{3}
 testam (\ref{mainti}). Ademais,
notemos que, para todo $j\in[k]$, o polinômio constante
      $\um(x)$
    é o único polinômio que divide ambos $g(x)$ e $x^{p^{m_j}}-x$ se e
    somente se
$(x-\alpha)(x^{p^{m_j}}-x)$ módulo $g(x)$, qualquer que seja $\alpha$
    raiz de $g(x)$ não é divisor de $g(x)$. Esse
    resultado pode ser facilmente demonstrado e garante que as linhas
    \texttt{4}--\texttt{9} testam (\ref{maintii}).

Um resultado bastante conhecido nos assegura que $x^{p^n}$ módulo $g(x)$
pode ser calculado com no máximo $2\log{p^n}$ multiplicações polinomiais
módulo
$g(x)$. Além disso, como computamos módulo $g(x)$, nunca precisamos
tratar de polinômios de grau maior que $2n$ durante o processo.

Em 1977, o alemão Schonhage\cite{schnelle} mostrou que a multiplicação
de dois polinômios de grau $n$ sobre corpos finitos pode ser feita em
$O(n\log{n}\log{\log{n}})$ operações do corpo. Por outro lado,
sabemos, como
mostrado em\xspace\cite{design}, que encontrar o resto da divisão de uma
multiplicação de polinômios de grau no máximo $n$ por um polinômio de
grau no máximo $n$ pode ser feito também em $O(n\log{n}\log{\log{n}})$
operações do corpo.
Assim, a linha \texttt{1} pode ser executada com
\begin{equation}\label{estimativasuper}
  O\bigl(2\log{p^n}(n\log{n}\log{\log{n}}+n\log{n}\log{\log{n}})\bigr) =
  O\bigl(n^2(\log{n}\log{\log{n}})\log{p}\bigr)
\end{equation}
operações de $\galois{p}$. Como as linhas \texttt{2}--\texttt{3}
podem ser executadas
em tempo constante, a estimativa\xspace\ref{estimativasuper} vale para
todo o conjunto de linhas \texttt{1}--\texttt{3}.

Também por causa dos mesmos resultados mostrados
por\xspace\cite{design}, podemos concluir que a linha \texttt{8} pode
ser executada com
\begin{equation*}
  O(n\log{n}\log{\log{n}}) +
  O(n\log{n}\log{\log{n}}) =
  O(n\log{n}\log{\log{n}})
\end{equation*}
operações de $\galois{p}$, estimativa que vale na realidade para todo o
conjunto de linhas \texttt{8}--\texttt{9}. Dessarte, como $g(x)$ possui
no máximo $n$ raízes, as linhas \texttt{7}--\texttt{9} podem ser
executadas
com $O(n^2\log{n}\log{\log{n}})$
operações em $\galois{p}$. Utilizando a mesma
argumentação que usamos para as linhas \texttt{1}--\texttt{3}, e
lembrando que $O(m^j)=O(n)$ para todo $j\in[k]$,
concluímos que as linhas \texttt{5}--\texttt{6} também podem ser
executadas com $O\bigl(n^2(\log{n}\log{\log{n}})\log{p}\bigr)$ operações
em $\galois{p}$. Finalmente, como $k\leq \log{n}$, temos que as linhas
\texttt{4}--\texttt{9} podem ser executadas com
\begin{equation*}
  O\bigl(\log{n}(
    n^2(\log{n}\log{\log{n}})\log{p} +
    n^2\log{n}\log{\log{n}}
    )\bigr) =
    O\bigl((n\log{n})^2(\log{\log{n}})\log{p}\bigr)\MMv
\end{equation*}
e, portanto, todo o algoritmo pode ser executado com
\begin{equation*}
  O\bigl(n^2(\log{n}\log{\log{n}})\log{p}\bigr) +
  O\bigl((n\log{n})^2(\log{\log{n}})\log{p}\bigr) =
  O\bigl((n\log{n})^2(\log{\log{n}})\log{p}\bigr)
\end{equation*}
operações sobre $\galois{p}$. Uma vez que cada operação sobre
$\galois{p}$, na medida em que representamos elementos de $\galois{p}$
por $O(\log{p})$ \textit{bits}, pode ser feita em
$O(\log{p}\log{\log{p}})$ operações elementares, chegamos à seguinte
estimativa para o tempo do algoritmo:
\begin{equation*}
  \begin{aligned}
  \simb[tempo de execução de um algoritmo com tamanho da entrada
  $n$]{T(n)}
  &=   O\bigl((n\log{n})^2(\log{\log{n}})\log{p}\bigr)
            O(\log{p}\log{\log{p}})\\
       &= O\bigl((n\log{n}(\log{\log{n}})\log{p})^2\bigr)\MMp
  \end{aligned}
\end{equation*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% alg.tex                                                              %
%                                                       fim do arquivo %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
