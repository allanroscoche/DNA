\chapter{Introdução}
Um pré-requisito para a compreensão completa da biologia de um organismo
é determinar toda a sua sequência genética. Agora nesse momento, há
vários projetos de sequenciamento genético em andamento para vários
organismos. Uma parte importante desses projetos é a montagem das partes do
DNA desses seres vivos, onde técnicas cada vez mais sofisticadas de computação vem
sendo utilizadas para superar esse desafio.

\section{Motivação}
Com o desenvolvimento de novos sequenciadores capazes de gerar vários
gigabytes de dados em algumas horas, os softwares necessitam cada vez
mais de sofisticações para conseguir lidar com esses dados. Vários
montadores foram criados para conseguir mostrar resultados em tempo
hábil, contudo máquinas cada vez mais poderosas são necessárias.
Montadores como o Velvet necessitam de quantidades cada vez maiores de
memória. Sendo que apenas computadores de grande porte conseguem atendem
as necessidades do software. Estudar as possibilidades de economia de
memória para que seja possível fazer o sequenciamento de seres maiores
nas máquinas atuais e a capacidade de fácil distribuição do trabalho
para que vários processadores possam trabalhar ao mesmo tempo.

\section{Objetivos}
O objetivo do projeto foi criar alguma modificação na criação da tabela
hash do velvet, de uma maneira que ela utilizasse menos memória e que
pudesse ser criada paralelamente de uma forma eficiente.

\section{Organização do Trabalho}
O capítulo 2 trata dos sequenciadores genéticos e como eles geram o
problema computacional da montagem, támbém realiza uma perspectiva
histórica de como o sequenciamento vem evoluindo. Já o capítulo 3 trata
do problema da montagem de uma forma geral e qual a complexidade
computacional para tratá-lo. O capítulo 4 trata o velvet e como ele
trata do problema da montagem. O capíutlo 5 mostra como foram
implementadas as alterações na tabela hash e como foi realizada a
paralelização. O capítulo 6 mostra os resultados obtidos.

\chapter{Sequenciamento}
\section{Sequenciamento Tradicional}
O sequenciamento consiste em se conseguir ``ler'' ou ``descobrir'' em que
ordem as bases nucléicas A,C,G,T se encontram no código genético de um organismo.
Para se conseguir ``ler'' essas bases vários métodos químicos são utilizados para
descobrir qual base está em que posição do código genético. Compostos químicos complementares
são misturados a solução com o DNA a ser sequenciado, em uns dos métodos átomos radioativos
eram utilizados para marcar cada base, e depois uma espécie de radiografia da sequencia era realizada.
A partir dessa idéia foram adicionados aos compostos complementares corantes fluorecentes, esses corantes
ao serem excitados com laser produziam uma intensidade de onde dependendo da base presente.
Com essa imagem, uma análise era feita das intensidade das cores para determinar a sequencia lida.
Um dos grandes problemas nesse método é distinguir a quantidade de n marcas consecutivas e qualidade
das ``fotografias'' geradas, por isso várias cópias eram geradas e sequenciadas.
Essas ``fotografias'' tiradas do código genético não são completas, ou seja, não contém todo o código genético
e sim uma parte dele. Uma comparação possível seria como tirar uma foto de um texto, há um compromisso entre
tamanho e qualidade, é possível fotografar todo o texto com uma qualidade pequena, imposibilitando a identificação
das letras, ou fotografar parágrafo por parágrafo, e a partir deles montar o texto completo. Tendo isso em vista
podemos analizar as duas formas tradicionais de sequenciamento.


\subsection{Sequenciamento Dirigido}
% www.elsevier.com/locate/jbiotec
% DOE92
% GUS97
% 20 linhas - 7
O método mais comum de sequenciamento dirigido é o primer walking. Esse
método consiste em identificar uma sequência conhecida, e a partir dela
ler a sequencia adjacente. Essa nova sequência então é utilizado para
identificar a próxima leitura e então uma nova sequencia é
gerada. Dessa maneira ``anda-se'' por toda a sequência e o cromossomo é
lido do começo ao fim.
Apesar da simplicidade teórica do método, a sua implementação é muito difícil e de custo alto.
Admitindo que uma sequencia já é conhecida, para conseguirmos a próxima sequencia é necessário
gerar um composto químico que ``encaixe'' com a parte final da sequencia conhecida para então
obter a continuação da sequencia. Alguns desses compostos químicos para ``encaixe'' poderiam difíceis
de serem produzidos, os tornando muitos caros, ou até mesmo raramente utilizados elevando o seu preço 
de produção. Aliado isso ao fato de que só era possível iniciar o sequenciamento de um fragmento depois
que outro já estivesse completo, torna esse método muito mais lendo que o sequenciamento aleatório.

\subsection{Sequenciamento Aleatório}
% MW96
% Mye99
% WM97
% Gre97
% Ms94
% 20 linhas - 8
A estratégia shotgun para o sequenciamento genético consiste em quebrar
 o DNA em segmentos de vários tamanhos e então clonar
esses segmentos em vetores. Esses segmentos então são sequenciados e
várias leituras aleatórias do organismo são geradas. Essas leituras
então são comparadas e montadas, gerando assim várias sequências maiores
chamadas de contigs. A combinação de todos os contigs então é realizada
para descobrir o DNA completo do organismo, normalmente técnicas de
sequenciamento dirigido é realizado para sequenciar as partes faltantes.
Uma das grandes vantages do sequenciamento aleatório sobre o dirigido é a
possibilidade de sequenciar várias partes do DNA ao mesmo tempo, sem a necessidade
de utilizar compostos para ``encaixar'' em algum ponto da sequencia. Assim, o trabalho
de ``montar'' o código genético completo não é mais realizado totalmente no
sequenciamento e sim através da utilização de softwares para ``montar'' ou
``encaixar'' esses fragmentos sequenciados.

\section{Sequenciadores de Nova Geração}
% 20 linhas - 14
Três plataformas para o sequenciamento massivamente paralelo como o
Roche/454 FLX, o Illumina/Solexa Genome Analizer e o Applied Biosystems
SOLiD System. Esses instrumentos permitem uma grande simplificação no
processo de preparação do sequenciamento do DNA, o que economiza tempo e
um requerimento menor assossiado aos equipamentos muito automatizados,
com muitos passos e baseados em clonagem. Por métodos diferentes, cada
tecnologia procura amplificar cada fita dos fragmentos de amostra e
realiza várias reações nelas.
Uma outra diferença das novas plataformas é a diferença do tempo
necessário para a geração dos dados. Os sequenciadores clássicos
necessivam de tempos entre 8 horas e 10 dias.
O rendimento dos dados dos experimentos também mudaram drasticamente, ao
ínvés de 96 leituras com até 750 nucleotídios cada. Os novos sequenciadores variam
entre centenas de milhares de leituras até 10 milhões de leituras.

\subsection{Sequeciamento com Referência}
No sequenciamento com referencia algum organismo da mesma espécie já foi
sequenciado, e através dele, as leituras são mapeadas para esse organismo
``exemplo''. O objetivo é encontrar as diferenças entre o organismo exemplo
e aquele em que está sendo sequenciado. O trabalho computacional concentra-se
apenas em comparar as sequencias lidas ao exemplo, e marcar o local onde 
os melhores encaixes são obtidos. Assim as bases nas leituras que não correspondem
ao código exemplo seriam a diferença entre os 2 organismos.


\subsection{Sequenciamento De Novo}
Inicialmente esses sequenciadores eram utilizados para sequenciar o
código genético de organismos já conhecidos. As leituras eram mapeadas
para um ``esqueleto'' já conhecido e através dele era montado o novo
código genético. Sequenciar o código genético de um organismo que ainda
não foi sequenciado, ou seja, em que não existe um ``esqueleto'' é
conhecido como sequenciamento De novo.
Uma das grandes dificuldades para realizar um sequenciamento de novo com
os sequenciadores de nova geração é o grande aumento no número de
leituras. Muitos softwares de montagem utilizados nos sequencidores
clássicos eram incapazes de trabalhar com esse novos dados. Novos montadores
foram criados para conseguir realizar um sequenciamento de novo com os
sequenciadores de nova geração.

\subsection{ABI Solid}



\chapter{Montagem}

\section{Montagem Tradicional}
%
%
Os sequenciadores conseguem ler apenas um número limitado de bases, esse
número limitado de bases é chamado de leitura. No sequenciamento
aleatório a posição da leitura é desconhecido e,  para descobrir a sua
posição, as leituras são comparadas entre si e organizadas para tentar
criar uma sequencia única. Nos sequenciadores clássicos as leituras
variavam normalmente entre 500 e 800 bp. Todas essas leituras devem ser
então ``encaixadas'' para se obter o código genético completo do
organismo. Para que as leituras sejam ``encaixadas'' é utilizado a
sobreposição de regiões repetidas nas leituras, como por exemplo

\subsection{Detecção da Sobreposição}
A detecção da sobreposição é realizada comparando o sufixo de uma
sequencia com o prefixo da outra sequencia. Numa sequencia sem erros
essa comparação poder ser realizada diretamente comparando as ultimas n
bases da primeira sequencia com as primeiras n bases da segunda
sequencia. Nos sequenciadores de primeira geração a taxa de erros era
muito alta, o que impossibilitava a comparação direta, então
a comparação entre duas leituras é realizada utilizado o algoritmo de
Smith e Waterman. O algorimo possui complexidade quadrática.


\subsection{Decisão da Sequência Consenso}
As leituras podem ser comparadas através de suas sobreposições, com elas
monta-se um grafo em que cada vértice é uma leitura e cada aresta
se existir uma sobreposição[pevzner] entre elas. O
algoritmo encontra a melhor sobreposição possível, com essa sobreposição é
dado um peso a aresta correspondente as duas leituras. O problema de
montagem é então modelado para o problema do Caminho Hamiltoniano, onde
cada vértice precisa ser visitado uma única vez. Utilizando esse caminho
e as sobreposições encontradas é montado uma sequencia única chamada de
contig. O grafo gerado não é necessariamente conexo, e para cada
componente conexa é gerada um contig. Após a primeira montagem podem ser
realizados novos sequenciamentos aleatórios para tentar montar um grafo
conexo ou sequenciamentos dirigidos podem ser utilizados para ``unir''
os contigs gerados.

\subsection{Problemas Existentes}
O problema do Caminho Hamiltoniado é NP-Completo e não existem
algoritmos eficientes para resolvê-lo. Contudo alguns programas utilizam
essa estratégia para a montagem dos fragmentos como o PHRAP, CAP, TIGR e
CELERA. Esses programas contudo só conseguem realizar a montagem para
sequenciadores de primeira geração onde o número de leituras eram perto
de 100 e cada leitura possuia entre 400bp e 900bp. Sequenciadores de
segunda geração como o ABI Solid geram em torno de 10 milhões leituras onde
cada leitura possui entre 35bp até 50bp. Devido ao grande
aumento no número de leituras esses programas não conseguem tratar em
tempo hábil o problema devido a natureza exponencial da estratégia da montagem.
%https://products.appliedbiosystems.com/ab/en/US/adirect/ab?cmd=catNavigate2&catID=600530&tab=DetailInfo




\section{Montagem Atual}
A abordagem atual para a montagem de fragmentos se baseia no grafo de
Bruijn. Em uma maneira simplificada nós podemos visualizar a construção
de um grafo de Bruijn representando as sequencias como um ``fio'' e as
regiões repetidas cobertas por uma ``cola'' que ``prende'' elas juntas.
Nessa representação cada repetição corresponde a uma aresta ao invés de
uma coleção de vértices.

\subsection{``Grude'' ou K-mers}
Uma das grandes dificuldades nesse método é a criação desses ``grudes'',
pois não há como saber com antecedência como as sequencias ``encaixam''
entre si no código final. Isso é realizado de uma maneira aproximada e
algoritmos para a correção de erros é utilizada para sanar imperfeições
na montagem realizadas nessa fase.

\subsection{Grafo de Bruijn}
O grafo de Bruijn é montado criando vértices que são partes repetidas de
leituras, ou seja, as leituras são unidas. Dessa maneira, cada repetição
corresponde a uma aresta ao invés de uma coleção de vértices no grafo
de sobreposições. O mais importante é que agora o problema de montagem é modelado em encontrar um
caminho em que cada aresta é visitada apenas uma vez, um problema do
Caminho Euleriano[Pevzner-2001]. Ao contrário do Caminho Hamiltoniano, o
problema do Caminho Euleriano possui uma complexidade menor, pois
existem algoritmos em rodam tem tempo linear. Essa é a fundamental
diferença entre as duas estratégias. Apesar do grafo de Bruijn possuir
vantagens em sua complexidade, não é muito claro como encontrar um jeito
de construí-lo. Os vértices criados através de leituras unidas necessita
do conhecimento do DNA completo, que não está disponível até a fase
final.

\subsection{Supercaminho Euleriano}
O problema do Supercaminho euleriano é definido como "Dado um grafo de Bruijn e uma colação de caminhos neste grafo,
 encontre um caminho Euleriano neste grafo que contenha todos estes caminhos como subcaminhos".
 Dada uma coleção de reads (cadeias) S={s1, s2, ..., sn} de um projeto de sequenciamento e um inteiro l,
 o spectrum de S é o conjunto Sl de todas as l-tuplas dos reads s1, s2, ..., sn. 
Uma (l-1)-tupla v E Sl-1 é ligado por uma aresta direcionada com (l-1)tupla w E Sl-1, 
se Sl contém uma l-tupla onde os primeiros l-1 nucleotídeos coincidem com os ultismos l-1 nucleotídeos de w.
 Cada l-tupla de Sl corresponde a uma aresta no grafo. Se S contem apenas uma sequencia S1 then essa sequencia
 corresponde a um caminho visitando cada aresta uma vez, esse problema é intimimamente relacionado ao problema
 de encontrar o caminho visitando cada aresta do grafo apenas uma vez, um problema do caminho euleriano.
 Nós podemos transformar o problema num caminho euleriano introduzindo multiplicidades
nas arestas do grafo de bruijn.
\subsection{Remoção de Erros}

\subsection{Problemas}

\chapter{O montador Velvet}

\section{Fases da Montagem}
O velvet é dividido em 2 executáveis, o velveth e velvetg, respectivamente
aquele que cria a tabela hash e o outro que cria o grafo. O trabalho foi focado
na primeira parte do programa, onde mudanças são propostas para tentar melhorar
a utilização de memória, paralização e tempo de execução. 

\section{Tabela de K-mers}
Os k-mers são os vértices do grafo de Bruijn no Velvet. Os k-mers são
formados por k-1 bases adjacentes. Cada nó é unido ao seu inverso,
que representa a ordem inversa do seu complemento dos nucleotídios. A
união do nó com seu inverso é chamado bloco. Cada bloco tem dois lados
distintos, cada lado é ligado por um ``arco'' direcionado. Contudo se um
arco vai de A pra B, um arco simétrico vai de /B pra /A. Os nós e os
arcos são mapenado como ``caminhos'' atravessando o grafo.[velvet]

\subsection{Tabela de Reads}
\subsection{Criação dos K-mers}
\subsection{Criação do RoadMap}


\section{Grafo de Bruijn}
É realizado uma hash das leituras de acordo com o tamanho definido pelos
k-mers. A variável k é limitada pelo tamanho da leitura sendo
utilizada. K-mers pequenos aumentam a conectividade do grapo ao mesmo
tempo aumentam a chance de repetições ambíguas no grafo. Logo é
necessário um equilibrio entre sensibilidade e especificidade
determinado pelo k(cf. Methods).
Para cada k-mers encontrado no conjunto de leituras, a tabela hash
armazena o ID da primeira leitura encontrada para aquele k-mer e a sua
posição encontrada dentro da leitura. Cada k-mer é armazenado
simultaneamente com o seu complemento reverso. Para garantir que cada
k-mer não possa ser o seu próprio complemento reverso, k tem que ser um
número impar. Essa primeira leitura permite que cada leitura seja
reescrita como um conjunto de k-mers combinados com suas sobreposições
na tabela hash. Essa representação de leituras é chamada de ``roadmap''
e é o foco do trabalho realizado.

\subsection{Criação do Grafo}

\subsection{Remoção de Erros}
A correção de erros é realizada depois que o grafo é formado para que
seja possível operações simultâneas no conjunto de leituras. Uma
abordagem simplista seria remover todos os nós com cobertura baixa,
contudo isso também eliminaria variações biológicas legítimas que tenham
uma representação baixa. O Velvet utiliza métodos que focam
características topológicas. Informações errôneas geram três tipos de
estruturas: ``tips'' em função dos erros nos arcos do reads, ``bulges''
devido a leituras erradas ou a ``tips'' próximas que estejam conectadas,
e conexões erradas devido a defeitos de clonagem. Os três erros são
removidos consecutivamente.

\subsection{Supercaminho Euleriano}

%\chapter{Falha de segurança no DNS}
%Em Julho de 2008 foi anunciado pelo \textit{CERT} (\textit{Computer Emergency Readiness Team} -- Time de prontidão a emergências computacionais) que o pesquisador de segurança Dan Kaminsky havia descoberto uma falha fundamental no protocolo do DNS, definido nos RFC's 1034 \cite{rfc1034} e 1035 \cite{rfc1035}.


\chapter{Implementações e Mudanças Realizadas no Velvet}

\section{Implementação Enxuta dos Reads}
A implementação das leituras é realizada de uma forma a economizar o
máximo de memória. Cada base de uma leitura utiliza apenas 2 bits por
base, num total de 4 nucleotídeos por byte. Utilizando 4 vezes menos
memória do que armazenar um nucleotídio por byte, formando um bloco com
4 bases.
Cada sequencia é armazenada com um vetor de tamanho n, onde o número de
nucleotídios é no máximo 4n. Dentro da estrutura é armazenado o
tabanho do vetor e qual a posição de término do ultimo nucleotídio da
ultima posição do vetor.

\section{Criação de K-mers reduzida}
A busca das sobreposições é realizada comparando bloco a bloco as
sequências. Ao invés de k-1 pares adjacentes, as sequencias são ligadas
comparando bloco a bloco até que uma quantidade mínima de blocos seja
igual. 

\section{Resultados}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Modelo para escrever TCCs, dissertações e teses utilizando LaTeX, ABNTeX e BibTeX
% Autor/E-Mail: Robinson Alves Lemos/contato@robinson.mat.br/robinson.a.l@bol.com.br
% Data: 19/04/2008 
% Colaboradore(s)/E-Mail(s):
% Caso queira colaborar, entre em contato pelo e-mail e informe alterações que realizou.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

